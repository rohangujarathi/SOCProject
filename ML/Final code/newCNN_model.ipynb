{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"newCNN_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"jOqhN9ISbIPQ","colab_type":"code","outputId":"c1f19241-91de-4995-b6bd-2eb0ab3ad1d8","executionInfo":{"status":"ok","timestamp":1543383846530,"user_tz":300,"elapsed":5398,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount= True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"metadata":{"id":"TUfo0LqjcoCU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"34345216-c3ba-4e6b-a1ea-a3b496d3227a","executionInfo":{"status":"ok","timestamp":1543384367721,"user_tz":300,"elapsed":14678,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}}},"cell_type":"code","source":["import numpy as np\n","import re\n","import itertools\n","from collections import Counter\n","\n","def load_data_and_labels():\n","  positive_examples = list(open(\"/content/drive/My Drive/Colab Notebooks/Datasets/positive.csv\").readlines())\n","  positive_examples = [s.strip() for s in positive_examples]\n","  negative_examples = list(open(\"/content/drive/My Drive/Colab Notebooks/Datasets/negative.csv\").readlines())\n","  negative_examples = [s.strip() for s in negative_examples]\n","  x_text = positive_examples + negative_examples\n","  x_text = [s.split(\" \") for s in x_text]\n","  positive_labels = [[0, 1] for _ in positive_examples]\n","  negative_labels = [[1, 0] for _ in negative_examples]\n","  y = np.concatenate([positive_labels, negative_labels], 0)\n","  print(y.shape, \"load data\")\n","  return [x_text, y]\n","\n","def pad_sentences(sentences, padding_word=\"<PAD/>\"):\n","  sequence_length = max(len(x) for x in sentences)\n","  padded_sentences = []\n","  for i in range(len(sentences)):\n","      sentence = sentences[i]\n","      num_padding = sequence_length - len(sentence)\n","      new_sentence = sentence + [padding_word] * num_padding\n","      padded_sentences.append(new_sentence)\n","  return padded_sentences\n","\n","def build_vocab(sentences):\n","    # Build vocabulary\n","    word_counts = Counter(itertools.chain(*sentences))\n","    # Mapping from index to word\n","    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n","    # Mapping from word to index\n","    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n","    return [vocabulary, vocabulary_inv]\n","\n","def build_input_data(sentences, labels, vocabulary):\n","    x = np.array([[vocabulary[word] for word in sentence] for sentence in sentences])\n","    y = np.array(labels)\n","    print(y.shape, \"build data\")\n","    return [x, y]\n","  \n","  \n","def load_data():\n","    \"\"\"\n","    Loads and preprocessed data for the MR dataset.\n","    Returns input vectors, labels, vocabulary, and inverse vocabulary.\n","    \"\"\"\n","    # Load and preprocess data\n","    sentences, labels = load_data_and_labels()\n","    sentences_padded = pad_sentences(sentences)\n","    vocabulary, vocabulary_inv = build_vocab(sentences_padded)\n","    x, y = build_input_data(sentences_padded, labels, vocabulary)\n","    return [x, y, vocabulary, vocabulary_inv]\n","  \n","x, y, vocabulary, vocabulary_inv_list = load_data()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(283967, 2) load data\n","(283967, 2) build data\n"],"name":"stdout"}]},{"metadata":{"id":"qM275JDY3A-J","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IaNM_HbpkXyJ","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install gensim\n","from gensim.models import word2vec\n","from os.path import join, exists, split\n","import os\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C05Zh5lmjSnz","colab_type":"code","outputId":"9c6f25f5-9945-4628-8f27-0e13ba02275d","executionInfo":{"status":"ok","timestamp":1543197954381,"user_tz":300,"elapsed":62858,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["def train_word2vec(sentence_matrix, vocabulary_inv,\n","                   num_features=100, min_word_count=30, context=10):\n","    \n","  # Set values for various parameters\n","  num_workers = 2  # Number of threads to run in parallel\n","  downsampling = 1e-3  # Downsample setting for frequent words\n","\n","  # Initialize and train the model\n","  print('Training Word2Vec model...')\n","  sentences = [[vocabulary_inv[w] for w in s] for s in sentence_matrix]\n","  embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n","                                      size=num_features, min_count=min_word_count,\n","                                      window=context, sample=downsampling)\n","\n","  # Saving the model for later use. You can load it later using Word2Vec.load()\n","  print('Saving Word2Vec model')\n","  embedding_model.save('/content/drive/My Drive/Colab Notebooks/Trained models/word2vec_model_count30')\n","\n","  # add unknown words\n","#   embedding_weights = {key: embedding_model[word] if word in embedding_model else\n","#                             np.random.uniform(-0.25, 0.25, embedding_model.vector_size)\n","#                        for key, word in vocabulary_inv.items()}\n","#   return embedding_weights\n","vocabulary_inv = {key: value for key, value in enumerate(vocabulary_inv_list)}\n","train_word2vec(x, vocabulary_inv)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Word2Vec model...\n","Saving Word2Vec model\n"],"name":"stdout"}]},{"metadata":{"id":"xs5vdtKbki5X","colab_type":"code","colab":{}},"cell_type":"code","source":["# import gensim\n","model = word2vec.Word2Vec.load('/content/drive/My Drive/Colab Notebooks/Trained models/word2vec_model_count30')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5gRv5Hivnlib","colab_type":"code","outputId":"c4c9413b-bdfe-490a-bb45-cfc7b191326d","executionInfo":{"status":"ok","timestamp":1543345442191,"user_tz":300,"elapsed":536,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# len(model.wv.vocab)\n","# vocabulary_inv_list[1691]\n","vocabulary['asshole']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1691"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"id":"wx7Fen5Ttgmu","colab_type":"code","outputId":"521ca77c-4c15-4575-88c0-be982d7bc7e4","executionInfo":{"status":"ok","timestamp":1543384399756,"user_tz":300,"elapsed":9643,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(283967, 2)"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"e115pFgDyof_","colab_type":"code","colab":{}},"cell_type":"code","source":["y = y.argmax(axis=1)\n","shuffle_indices = np.random.permutation(np.arange(len(y)))\n","x = x[shuffle_indices]\n","y = y[shuffle_indices]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eC45X8Zg2p-T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"295d211e-104c-4e90-af3b-4c2dfbff7e35","executionInfo":{"status":"ok","timestamp":1543384430719,"user_tz":300,"elapsed":332,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}}},"cell_type":"code","source":["y.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(283967,)"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"vuCxvlr_ywuy","colab_type":"code","outputId":"2c43b76c-10c8-46f6-8a21-7968103cf50b","executionInfo":{"status":"ok","timestamp":1543383933150,"user_tz":300,"elapsed":4602,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["train_len = int(len(x) * 0.8)\n","x_train = x[:train_len]\n","y_train = y[:train_len]\n","x_test = x[train_len:]\n","y_test = y[train_len:]\n","print(\"x_train shape:\", x_train.shape)\n","print(\"x_test shape:\", x_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["x_train shape: (227173, 76)\n","x_test shape: (56794, 76)\n","y_train shape: (227173,)\n","y_test shape: (56794,)\n"],"name":"stdout"}]},{"metadata":{"id":"lWcazeA14sp7","colab_type":"code","colab":{}},"cell_type":"code","source":["vocabulary_inv = {key: value for key, value in enumerate(vocabulary_inv_list)}\n","embedding_weights = {key: model[word] if word in model else\n","                            np.random.uniform(-0.25, 0.25, model.vector_size)\n","                       for key, word in vocabulary_inv.items()}\n","weights = np.array([v for v in embedding_weights.values()])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UaW9L6g06aXC","colab_type":"code","outputId":"2e320bec-027d-4107-bc3f-cf6d0a7f26dd","executionInfo":{"status":"ok","timestamp":1543286935774,"user_tz":300,"elapsed":2190,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(weights)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["373311"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"p_xKsQ_dFQsG","colab_type":"code","outputId":"ca89df26-3cc4-430d-f7e6-dc6bb80184b5","executionInfo":{"status":"ok","timestamp":1543345927842,"user_tz":300,"elapsed":1542,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","from keras.preprocessing import text, sequence\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"aXU27zq7JruL","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers.merge import Concatenate"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tGzavUyqqpn6","colab_type":"code","outputId":"2f6c265e-217d-4add-e812-e8f7718757d4","executionInfo":{"status":"ok","timestamp":1543287018160,"user_tz":300,"elapsed":2577,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"cell_type":"code","source":["max_features = len(vocabulary_inv_list)\n","embedding_dims = 100\n","max_text_length = x_test.shape[1]\n","filters = 10\n","kernel_size = 3\n","hidden_dims = 50\n","\n","\n","model = Sequential()\n","\n","print('Build model...')\n","\n","\n","# we start off with an efficient embedding layer which maps\n","# our vocab indices into embedding_dims dimensions\n","model.add(Embedding(max_features,\n","                    embedding_dims,\n","                    input_length=max_text_length, weights = [weights]))\n","model.add(Dropout(0.2))\n","\n","# we add a Convolution1D, which will learn filters\n","# word group filters of size filter_length:\n","\n","# submodels = []\n","# for ks in kernel_size:\n","#   submodel = Sequential()\n","model.add(Conv1D(filters,\n","                   kernel_size,\n","                   padding='valid',\n","                   activation='relu',\n","                   strides=1))\n","model.add(GlobalMaxPooling1D())\n","#   submodels.append(submodel)\n","\n","# z = Concatenate()(submodels)\n","# model.add(z)\n","# we use max pooling:\n","# model.add(GlobalMaxPooling1D())\n","model.add(Dropout(0.5))\n","# We add a vanilla hidden layer:\n","model.add(Dense(hidden_dims))\n","model.add(Activation('relu'))\n","\n","# We project onto 6 output layers, and squash it with a sigmoid:\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build model...\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 76, 100)           37331100  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 76, 100)           0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 74, 10)            3010      \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 10)                0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 10)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 50)                550       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 50)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 51        \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 37,334,711\n","Trainable params: 37,334,711\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"gzEZRdYIQ6ol","colab_type":"code","outputId":"42528e08-f764-402c-a02c-b2ce8aa7f322","executionInfo":{"status":"ok","timestamp":1543349811697,"user_tz":300,"elapsed":376,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"cell_type":"code","source":["print(type(x_test[0][0]))\n","print(x_test[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'numpy.int64'>\n","[243704      7     35      4      1    530      6      1    310      4\n","     55    263      3    341     11    311    646    563     47      4\n","    218   2697      4     38    737     25      1    240     71      5\n","   1822     47      4    218   2697      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0]\n"],"name":"stdout"}]},{"metadata":{"id":"7uMvbFoAQqic","colab_type":"code","outputId":"a28e2412-fdc3-4c00-df5d-2fa148e584c0","executionInfo":{"status":"ok","timestamp":1543289968932,"user_tz":300,"elapsed":825809,"user":{"displayName":"Rohan Gujarathi","photoUrl":"","userId":"12179700570471465676"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=512, epochs=10, validation_data=(x_test, y_test),  shuffle=True, verbose = 1)\n","model.save('/content/drive/My Drive/Colab Notebooks/Trained models/CNN_onekernel.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 227173 samples, validate on 56794 samples\n","Epoch 1/10\n","227173/227173 [==============================] - 294s 1ms/step - loss: 0.5136 - acc: 0.7444 - val_loss: 0.4117 - val_acc: 0.8497\n","Epoch 2/10\n","227173/227173 [==============================] - 291s 1ms/step - loss: 0.3836 - acc: 0.8292 - val_loss: 0.3819 - val_acc: 0.8723\n","Epoch 3/10\n","227173/227173 [==============================] - 292s 1ms/step - loss: 0.3422 - acc: 0.8516 - val_loss: 0.3715 - val_acc: 0.8829\n","Epoch 4/10\n","227173/227173 [==============================] - 292s 1ms/step - loss: 0.3121 - acc: 0.8656 - val_loss: 0.3291 - val_acc: 0.8968\n","Epoch 5/10\n","227173/227173 [==============================] - 293s 1ms/step - loss: 0.2864 - acc: 0.8780 - val_loss: 0.3189 - val_acc: 0.9000\n","Epoch 6/10\n","227173/227173 [==============================] - 290s 1ms/step - loss: 0.2659 - acc: 0.8889 - val_loss: 0.3170 - val_acc: 0.9003\n","Epoch 7/10\n","227173/227173 [==============================] - 291s 1ms/step - loss: 0.2483 - acc: 0.8975 - val_loss: 0.3230 - val_acc: 0.9009\n","Epoch 8/10\n","227173/227173 [==============================] - 296s 1ms/step - loss: 0.2307 - acc: 0.9055 - val_loss: 0.2869 - val_acc: 0.9030\n","Epoch 9/10\n","227173/227173 [==============================] - 293s 1ms/step - loss: 0.2160 - acc: 0.9126 - val_loss: 0.2784 - val_acc: 0.9025\n","Epoch 10/10\n","227173/227173 [==============================] - 293s 1ms/step - loss: 0.1997 - acc: 0.9183 - val_loss: 0.2829 - val_acc: 0.9006\n"],"name":"stdout"}]}]}